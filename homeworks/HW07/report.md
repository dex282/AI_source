
# HW07 Report

## 1. Datasets
- **Dataset 1**: Датасет с признаками разного масштаба.
- **Dataset 2**: Датасет с нелинейной структурой кластеров.
- **Dataset 4**: Комплексный датасет с пропусками и категориальными признаками.

## 2. Protocol
Для каждого датасета применялся препроцессинг (масштабирование, импутация, кодирование) с помощью `sklearn.pipeline`. 
Гиперпараметры для `KMeans`, `AgglomerativeClustering` и `DBSCAN` подбирались по сетке с целью максимизации `silhouette_score`. 
Качество оценивалось по метрикам `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`.

## 3. Models & Results

### Dataset 1
Для Dataset 1 лучшим алгоритмом оказался KMeans с k=2.

### Dataset 2
Для Dataset 2 лучшей моделью оказался KMeans, который смог выделить нелинейные кластеры.

### Dataset 4
Для сложного Dataset 4 лучшей моделью стал Agglomerative с параметрами {'n_clusters': 5, 'linkage': 'ward'}.

## 4. Analysis

### Устойчивость

Проверка устойчивости проводилась для KMeans (k=2) на Dataset 1.
Было выполнено 5 запусков с разными `random_state`.
Попарное сравнение результатов с помощью Adjusted Rand Index (ARI) показало среднее значение **1.0000** со стандартным отклонением 0.0000.
Такое высокое значение ARI, близкое к 1, свидетельствует о **высокой устойчивости** модели. Это означает, что алгоритм стабильно находит одну и ту же структуру в данных независимо от начальной инициализации центроидов.


## 5. Conclusion
1.  **Препроцессинг критически важен**: Без масштабирования и обработки пропусков/категорий результаты кластеризации некорректны.
2.  **Выбор алгоритма зависит от данных**: `KMeans` хорош для сферических кластеров, `DBSCAN` — для кластеров произвольной формы и данных с шумом.
3.  **Визуализация — ключ к интерпретации**: PCA-графики позволяют визуально оценить качество разделения и подтвердить или опровергнуть выводы, сделанные на основе метрик.
